{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "title",
   "metadata": {},
   "source": [
    "# Comprehensive DuckDB Analysis\n",
    "\n",
    "## Carrier Invoice Dataset Analysis\n",
    "\n",
    "This notebook provides a comprehensive analysis of the DuckDB file generated by our ClickHouse extraction pipeline.\n",
    "\n",
    "### Analysis Scope:\n",
    "1. **Database Structure** - Tables, schemas, columns, data types\n",
    "2. **Data Statistics** - Record counts, date ranges, unique identifiers\n",
    "3. **Data Quality Metrics** - Completeness, null values, data integrity\n",
    "4. **File Information** - Size, location, extraction metadata\n",
    "\n",
    "Let's dive in! ðŸ”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "imports_setup",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“Š Libraries imported successfully!\n",
      "ðŸ¦† DuckDB version: 1.3.2\n",
      "ðŸ¼ Pandas version: 2.3.1\n"
     ]
    }
   ],
   "source": [
    "# Import required libraries\n",
    "import duckdb\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "\n",
    "# Display settings for better output\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', None)\n",
    "pd.set_option('display.max_colwidth', 50)\n",
    "\n",
    "print(\"ðŸ“Š Libraries imported successfully!\")\n",
    "print(f\"ðŸ¦† DuckDB version: {duckdb.__version__}\")\n",
    "print(f\"ðŸ¼ Pandas version: {pd.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "connect_duckdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”— Connecting to DuckDB Analysis\n",
      "========================================\n",
      "ðŸ“ File Location: c:\\Users\\Gabriel\\Documents\\gsr_project\\gsr_automation\\carrier_invoice_extraction.duckdb\n",
      "ðŸ’¾ File Size: 24.51 MB\n",
      "ðŸ•’ Last Modified: 2025-09-08 19:49:20\n",
      "\n",
      "âœ… Successfully connected to DuckDB!\n"
     ]
    }
   ],
   "source": [
    "# Connect to the DuckDB file\n",
    "db_path = \"../../carrier_invoice_extraction.duckdb\"\n",
    "\n",
    "print(\"ðŸ”— Connecting to DuckDB Analysis\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "try:\n",
    "    # Check if file exists\n",
    "    if not os.path.exists(db_path):\n",
    "        print(f\"âŒ DuckDB file not found: {db_path}\")\n",
    "        print(\"ðŸ’¡ Run the pipeline first: poetry run python src/src/dlt_pipeline_examples.py\")\n",
    "        raise FileNotFoundError(f\"DuckDB file not found: {db_path}\")\n",
    "    \n",
    "    # Get file information\n",
    "    file_stats = os.stat(db_path)\n",
    "    file_size_mb = file_stats.st_size / (1024 * 1024)\n",
    "    last_modified = datetime.fromtimestamp(file_stats.st_mtime)\n",
    "    \n",
    "    print(f\"ðŸ“ File Location: {os.path.abspath(db_path)}\")\n",
    "    print(f\"ðŸ’¾ File Size: {file_size_mb:.2f} MB\")\n",
    "    print(f\"ðŸ•’ Last Modified: {last_modified.strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "    \n",
    "    # Connect to DuckDB\n",
    "    conn = duckdb.connect(db_path)\n",
    "    print(f\"\\nâœ… Successfully connected to DuckDB!\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"âŒ Connection failed: {e}\")\n",
    "    conn = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "database_structure",
   "metadata": {},
   "source": [
    "## 1. Database Structure Analysis\n",
    "\n",
    "Examining the database schema, tables, and column structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "analyze_structure",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ—ï¸ Database Structure Analysis\n",
      "===================================\n",
      "ðŸ“‹ Available Schemas:\n",
      "   1. information_schema\n",
      "   2. main\n",
      "   3. main\n",
      "   4. main\n",
      "   5. pg_catalog\n",
      "\n",
      "ðŸ“Š Available Tables:\n",
      "   1. main.carrier_invoice_data (BASE TABLE)\n",
      "\n",
      "ðŸŽ¯ Main Table: carrier_invoice_extraction.carrier_invoice_data\n",
      "âŒ Main table carrier_invoice_extraction.carrier_invoice_data not found\n",
      "ðŸ’¡ Available tables listed above\n"
     ]
    }
   ],
   "source": [
    "# Analyze database structure\n",
    "print(\"ðŸ—ï¸ Database Structure Analysis\")\n",
    "print(\"=\" * 35)\n",
    "\n",
    "if conn is None:\n",
    "    print(\"âŒ No database connection available\")\n",
    "else:\n",
    "    try:\n",
    "        # 1. List all schemas\n",
    "        print(\"ðŸ“‹ Available Schemas:\")\n",
    "        schemas = conn.execute(\"SELECT schema_name FROM information_schema.schemata ORDER BY schema_name\").fetchall()\n",
    "        for i, schema in enumerate(schemas, 1):\n",
    "            print(f\"   {i}. {schema[0]}\")\n",
    "        \n",
    "        # 2. List all tables\n",
    "        print(f\"\\nðŸ“Š Available Tables:\")\n",
    "        tables = conn.execute(\"\"\"\n",
    "            SELECT table_schema, table_name, table_type \n",
    "            FROM information_schema.tables \n",
    "            WHERE table_schema NOT IN ('information_schema', 'pg_catalog')\n",
    "            ORDER BY table_schema, table_name\n",
    "        \"\"\").fetchall()\n",
    "        \n",
    "        for i, table in enumerate(tables, 1):\n",
    "            print(f\"   {i}. {table[0]}.{table[1]} ({table[2]})\")\n",
    "        \n",
    "        # 3. Focus on the main carrier invoice table\n",
    "        main_table = \"carrier_invoice_extraction.carrier_invoice_data\"\n",
    "        print(f\"\\nðŸŽ¯ Main Table: {main_table}\")\n",
    "        \n",
    "        # Check if main table exists\n",
    "        table_exists = conn.execute(f\"\"\"\n",
    "            SELECT COUNT(*) FROM information_schema.tables \n",
    "            WHERE table_schema = 'carrier_invoice_data' \n",
    "            AND table_name = 'carrier_invoice_data'\n",
    "        \"\"\").fetchone()[0]\n",
    "        \n",
    "        if table_exists == 0:\n",
    "            print(f\"âŒ Main table {main_table} not found\")\n",
    "            print(\"ðŸ’¡ Available tables listed above\")\n",
    "        else:\n",
    "            print(f\"âœ… Main table {main_table} found\")\n",
    "            \n",
    "            # Get basic table info\n",
    "            row_count = conn.execute(f\"SELECT COUNT(*) FROM {main_table}\").fetchone()[0]\n",
    "            print(f\"ðŸ“Š Total Records: {row_count:,}\")\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Structure analysis failed: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "analyze_columns",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“‹ Column Structure Analysis\n",
      "==============================\n",
      "âŒ No column information found for carrier_invoice_extraction.carrier_invoice_data\n"
     ]
    }
   ],
   "source": [
    "# Detailed column analysis\n",
    "print(\"ðŸ“‹ Column Structure Analysis\")\n",
    "print(\"=\" * 30)\n",
    "\n",
    "if conn is None:\n",
    "    print(\"âŒ No database connection available\")\n",
    "else:\n",
    "    try:\n",
    "        main_table = \"carrier_invoice_extraction.carrier_invoice_data\"\n",
    "\n",
    "        # Get column information\n",
    "        columns_info = conn.execute(f\"\"\"\n",
    "            SELECT \n",
    "                column_name,\n",
    "                data_type,\n",
    "                is_nullable,\n",
    "                column_default,\n",
    "                ordinal_position\n",
    "            FROM information_schema.columns \n",
    "            WHERE table_schema = 'carrier_invoice_data' \n",
    "            AND table_name = 'carrier_invoice_data'\n",
    "            ORDER BY ordinal_position\n",
    "        \"\"\").fetchall()\n",
    "\n",
    "        if not columns_info:\n",
    "            print(f\"âŒ No column information found for {main_table}\")\n",
    "        else:\n",
    "            print(f\"ðŸ“Š Total Columns: {len(columns_info)}\")\n",
    "            print(f\"\\nðŸ“‹ Column Details:\")\n",
    "\n",
    "            # Create DataFrame for better display\n",
    "            df_columns = pd.DataFrame(columns_info, columns=[\n",
    "                'Column Name', 'Data Type', 'Nullable', 'Default', 'Position'\n",
    "            ])\n",
    "\n",
    "            # Show first 20 columns\n",
    "            print(f\"\\nðŸ” First 20 Columns:\")\n",
    "            print(df_columns.head(20).to_string(index=False))\n",
    "\n",
    "            if len(df_columns) > 20:\n",
    "                print(f\"\\n... and {len(df_columns) - 20} more columns\")\n",
    "\n",
    "            # Data type summary\n",
    "            print(f\"\\nðŸ“Š Data Type Summary:\")\n",
    "            type_counts = df_columns['Data Type'].value_counts()\n",
    "            for dtype, count in type_counts.items():\n",
    "                print(f\"   {dtype}: {count} columns\")\n",
    "\n",
    "            # Key business columns\n",
    "            key_columns = [\n",
    "                'invoice_number', 'invoice_date', 'invoice_amount', 'invoice_currency_code',\n",
    "                'tracking_number', 'sender_company_name', 'receiver_company_name',\n",
    "                'charge_description', 'net_amount', 'import_time', '_extracted_at'\n",
    "            ]\n",
    "\n",
    "            print(f\"\\nðŸ’¼ Key Business Columns:\")\n",
    "            for col in key_columns:\n",
    "                col_info = df_columns[df_columns['Column Name'] == col]\n",
    "                if not col_info.empty:\n",
    "                    dtype = col_info.iloc[0]['Data Type']\n",
    "                    print(f\"   âœ… {col:25} | {dtype}\")\n",
    "                else:\n",
    "                    print(f\"   âŒ {col:25} | Not found\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Column analysis failed: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "data_statistics",
   "metadata": {},
   "source": [
    "## 2. Data Statistics Analysis\n",
    "\n",
    "Examining record counts, date ranges, and key identifier statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "basic_statistics",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“Š Data Statistics Analysis\n",
      "==============================\n",
      "ðŸ“ˆ Record Count Analysis:\n",
      "   Total Records: 144,910\n",
      "\n",
      "ðŸ“… Date Range Analysis:\n",
      "   Invoice Date Range: 2025-08-09 to 2025-08-09\n",
      "   Unique Invoice Dates: 1\n",
      "   Import Time Range: 2025-08-10 10:53:22.183318+08:00 to 2025-08-11 20:05:49.820707+08:00\n",
      "   Extraction Time Range: 2025-08-19 07:51:11.929653+08:00 to 2025-08-19 07:52:05.785236+08:00\n",
      "\n",
      "ðŸ”‘ Unique Identifier Analysis:\n",
      "   Invoice Numbers: 178\n",
      "   Tracking Numbers: 32,384\n",
      "   Account Numbers: 178\n",
      "   Sender Companies: 1,450\n",
      "   Receiver Companies: 24,212\n"
     ]
    }
   ],
   "source": [
    "# Basic data statistics\n",
    "print(\"ðŸ“Š Data Statistics Analysis\")\n",
    "print(\"=\" * 30)\n",
    "\n",
    "if conn is None:\n",
    "    print(\"âŒ No database connection available\")\n",
    "else:\n",
    "    try:\n",
    "        main_table = \"carrier_invoice_extraction.carrier_invoice_data\"\n",
    "\n",
    "        # 1. Basic record counts\n",
    "        print(\"ðŸ“ˆ Record Count Analysis:\")\n",
    "        total_records = conn.execute(f\"SELECT COUNT(*) FROM {main_table}\").fetchone()[0]\n",
    "        print(f\"   Total Records: {total_records:,}\")\n",
    "\n",
    "        # 2. Date range analysis\n",
    "        print(f\"\\nðŸ“… Date Range Analysis:\")\n",
    "\n",
    "        # Check invoice_date\n",
    "        try:\n",
    "            date_stats = conn.execute(f\"\"\"\n",
    "                SELECT \n",
    "                    MIN(invoice_date) as earliest_invoice,\n",
    "                    MAX(invoice_date) as latest_invoice,\n",
    "                    COUNT(DISTINCT invoice_date) as unique_dates\n",
    "                FROM {main_table}\n",
    "                WHERE invoice_date IS NOT NULL AND invoice_date != ''\n",
    "            \"\"\").fetchone()\n",
    "\n",
    "            print(f\"   Invoice Date Range: {date_stats[0]} to {date_stats[1]}\")\n",
    "            print(f\"   Unique Invoice Dates: {date_stats[2]:,}\")\n",
    "        except Exception as e:\n",
    "            print(f\"   âŒ Invoice date analysis failed: {e}\")\n",
    "\n",
    "        # Check import_time\n",
    "        try:\n",
    "            import_stats = conn.execute(f\"\"\"\n",
    "                SELECT \n",
    "                    MIN(import_time) as earliest_import,\n",
    "                    MAX(import_time) as latest_import\n",
    "                FROM {main_table}\n",
    "                WHERE import_time IS NOT NULL\n",
    "            \"\"\").fetchone()\n",
    "\n",
    "            print(f\"   Import Time Range: {import_stats[0]} to {import_stats[1]}\")\n",
    "        except Exception as e:\n",
    "            print(f\"   âŒ Import time analysis failed: {e}\")\n",
    "\n",
    "        # Check _extracted_at\n",
    "        try:\n",
    "            extract_stats = conn.execute(f\"\"\"\n",
    "                SELECT \n",
    "                    MIN(_extracted_at) as earliest_extraction,\n",
    "                    MAX(_extracted_at) as latest_extraction\n",
    "                FROM {main_table}\n",
    "                WHERE _extracted_at IS NOT NULL\n",
    "            \"\"\").fetchone()\n",
    "\n",
    "            print(f\"   Extraction Time Range: {extract_stats[0]} to {extract_stats[1]}\")\n",
    "        except Exception as e:\n",
    "            print(f\"   âŒ Extraction time analysis failed: {e}\")\n",
    "\n",
    "        # 3. Unique identifier counts\n",
    "        print(f\"\\nðŸ”‘ Unique Identifier Analysis:\")\n",
    "\n",
    "        identifiers = [\n",
    "            ('invoice_number', 'Invoice Numbers'),\n",
    "            ('tracking_number', 'Tracking Numbers'),\n",
    "            ('account_number', 'Account Numbers'),\n",
    "            ('sender_company_name', 'Sender Companies'),\n",
    "            ('receiver_company_name', 'Receiver Companies')\n",
    "        ]\n",
    "\n",
    "        for col_name, display_name in identifiers:\n",
    "            try:\n",
    "                unique_count = conn.execute(f\"\"\"\n",
    "                    SELECT COUNT(DISTINCT {col_name}) \n",
    "                    FROM {main_table}\n",
    "                    WHERE {col_name} IS NOT NULL AND {col_name} != ''\n",
    "                \"\"\").fetchone()[0]\n",
    "\n",
    "                print(f\"   {display_name}: {unique_count:,}\")\n",
    "            except Exception as e:\n",
    "                print(f\"   âŒ {display_name}: Analysis failed\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Statistics analysis failed: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cef1769f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           tracking_number transaction_date invoice_date\n",
      "0       1Z2F6Y330335239010       2025-08-04   2025-08-09\n",
      "1       1Z2F6Y330307908224       2025-07-31   2025-08-09\n",
      "2                                2025-08-09   2025-08-09\n",
      "3       1Z2F6Y330337780896       2025-08-05   2025-08-09\n",
      "4       1Z2F6Y330337780896       2025-08-05   2025-08-09\n",
      "...                    ...              ...          ...\n",
      "144905  1ZTT55371394846134       2025-08-06   2025-08-09\n",
      "144906  1ZTT55371394846134       2025-08-06   2025-08-09\n",
      "144907  1ZTT55370397867107       2025-08-06   2025-08-09\n",
      "144908  1ZTT55370398542152       2025-08-06   2025-08-09\n",
      "144909  1ZTT55370391395440       2025-08-05   2025-08-09\n",
      "\n",
      "[144910 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "query = f\"\"\"SELECT \n",
    "    tracking_number,\n",
    "    invoice_date,\n",
    "    shipment_date,\n",
    "    transaction_date,\n",
    "    STRFTIME(\n",
    "        COALESCE(\n",
    "            TRY_STRPTIME(invoice_date, '%Y-%m-%d'),\n",
    "            TRY_STRPTIME(invoice_date, '%m/%d/%Y')\n",
    "        ),\n",
    "        '%Y-%m-%d'\n",
    "    ) AS standardized_invoice_date\n",
    "FROM {main_table}\n",
    "WHERE COALESCE(\n",
    "    TRY_STRPTIME(transaction_date, '%Y-%m-%d'),\n",
    "    TRY_STRPTIME(transaction_date, '%m/%d/%Y')\n",
    ") >= CURRENT_DATE - INTERVAL '7 days';\n",
    "        \"\"\"\n",
    "\n",
    "query_1 = f\"\"\"\n",
    "    select \n",
    "    COUNT(CASE WHEN shipment_date IS NULL THEN 1 END)  as null_count,\n",
    "    COUNT(CASE WHEN shipment_date IS NOT NULL THEN 1 END) AS not_null_count\n",
    "    from {main_table}\n",
    "    ;\n",
    "\"\"\"\n",
    "\n",
    "query_3 = f\"\"\"\n",
    "    select tracking_number,transaction_date, invoice_date, \n",
    "    from {main_table}\n",
    "    \n",
    "    ;\n",
    "\"\"\"\n",
    "\n",
    "query_4 = f\"\"\"\n",
    "    SELECT COUNT(DISTINCT tracking_number) AS tracking_count\n",
    "FROM {main_table}\n",
    "WHERE DATE(\n",
    "        CASE \n",
    "            WHEN transaction_date LIKE '%/%/%' \n",
    "                 THEN STRFTIME('%Y-%m-%d', STRPTIME(transaction_date, '%m/%d/%Y'))\n",
    "            WHEN transaction_date LIKE '%-%-%' \n",
    "                 THEN STRFTIME('%Y-%m-%d', STRPTIME(transaction_date, '%Y-%m-%d'))\n",
    "        END\n",
    "      ) >= CURRENT_DATE - INTERVAL 20 DAY;\n",
    "    ;\n",
    "\"\"\"\n",
    "\n",
    "query_5 = f\"\"\"\n",
    "    SELECT COUNT(DISTINCT tracking_number) AS tracking_count\n",
    "FROM {main_table}\n",
    "    ;\n",
    "\"\"\"\n",
    "\n",
    "# Run query and directly convert to a Pandas DataFrame\n",
    "df = conn.execute(query_3).df()\n",
    "\n",
    "print(df)\n",
    "# df.to_csv(\"shipment_invoice_date.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e4784433",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "columns_info = conn.execute(\n",
    "    f\"\"\"\n",
    "            SELECT \n",
    "                column_name,\n",
    "                data_type,\n",
    "                is_nullable,\n",
    "                column_default,\n",
    "                ordinal_position\n",
    "            FROM information_schema.columns \n",
    "            WHERE table_schema = 'carrier_invoice_data' \n",
    "            AND table_name = 'carrier_invoice_data'\n",
    "            ORDER BY ordinal_position\n",
    "        \"\"\"\n",
    ").fetchall()\n",
    "\n",
    "print(columns_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "currency_analysis",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ’° Currency & Amount Analysis\n",
      "================================\n",
      "ðŸ’± Currency Distribution:\n",
      "âŒ Currency analysis failed: Catalog Error: Table with name carrier_invoice_data does not exist!\n",
      "Did you mean \"carrier_invoice_extraction.carrier_invoice_data\"?\n",
      "\n",
      "LINE 6:             FROM carrier_invoice_extraction.carrier_invoice_data\n",
      "                         ^\n"
     ]
    }
   ],
   "source": [
    "# Currency and amount analysis\n",
    "print(\"ðŸ’° Currency & Amount Analysis\")\n",
    "print(\"=\" * 32)\n",
    "\n",
    "if conn is None:\n",
    "    print(\"âŒ No database connection available\")\n",
    "else:\n",
    "    try:\n",
    "        main_table = \"carrier_invoice_extraction.carrier_invoice_data\"\n",
    "        \n",
    "        # Currency distribution\n",
    "        print(\"ðŸ’± Currency Distribution:\")\n",
    "        currencies = conn.execute(f\"\"\"\n",
    "            SELECT \n",
    "                invoice_currency_code,\n",
    "                COUNT(*) as count,\n",
    "                ROUND(COUNT(*) * 100.0 / SUM(COUNT(*)) OVER(), 2) as percentage\n",
    "            FROM {main_table}\n",
    "            WHERE invoice_currency_code IS NOT NULL AND invoice_currency_code != ''\n",
    "            GROUP BY invoice_currency_code\n",
    "            ORDER BY count DESC\n",
    "            LIMIT 10\n",
    "        \"\"\").fetchall()\n",
    "        \n",
    "        for curr in currencies:\n",
    "            print(f\"   {curr[0]:5} | {curr[1]:,} records ({curr[2]}%)\")\n",
    "        \n",
    "        # Amount statistics\n",
    "        print(f\"\\nðŸ’µ Invoice Amount Statistics:\")\n",
    "        try:\n",
    "            amount_stats = conn.execute(f\"\"\"\n",
    "                SELECT \n",
    "                    COUNT(*) as total_with_amounts,\n",
    "                    ROUND(AVG(CAST(invoice_amount AS DECIMAL)), 2) as avg_amount,\n",
    "                    ROUND(MIN(CAST(invoice_amount AS DECIMAL)), 2) as min_amount,\n",
    "                    ROUND(MAX(CAST(invoice_amount AS DECIMAL)), 2) as max_amount,\n",
    "                    ROUND(SUM(CAST(invoice_amount AS DECIMAL)), 2) as total_amount\n",
    "                FROM {main_table}\n",
    "                WHERE invoice_amount IS NOT NULL \n",
    "                AND invoice_amount != ''\n",
    "                AND TRY_CAST(invoice_amount AS DECIMAL) IS NOT NULL\n",
    "                AND CAST(invoice_amount AS DECIMAL) >= 0\n",
    "            \"\"\").fetchone()\n",
    "            \n",
    "            print(f\"   Records with Valid Amounts: {amount_stats[0]:,}\")\n",
    "            print(f\"   Average Amount: ${amount_stats[1]:,.2f}\")\n",
    "            print(f\"   Minimum Amount: ${amount_stats[2]:,.2f}\")\n",
    "            print(f\"   Maximum Amount: ${amount_stats[3]:,.2f}\")\n",
    "            print(f\"   Total Amount: ${amount_stats[4]:,.2f}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"   âŒ Amount statistics failed: {e}\")\n",
    "        \n",
    "        # Top charge types\n",
    "        print(f\"\\nðŸ“‹ Top Charge Types:\")\n",
    "        try:\n",
    "            charges = conn.execute(f\"\"\"\n",
    "                SELECT \n",
    "                    charge_description,\n",
    "                    COUNT(*) as count\n",
    "                FROM {main_table}\n",
    "                WHERE charge_description IS NOT NULL AND charge_description != ''\n",
    "                GROUP BY charge_description\n",
    "                ORDER BY count DESC\n",
    "                LIMIT 10\n",
    "            \"\"\").fetchall()\n",
    "            \n",
    "            for charge in charges:\n",
    "                print(f\"   {charge[0][:40]:40} | {charge[1]:,} records\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"   âŒ Charge analysis failed: {e}\")\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Currency analysis failed: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "data_quality",
   "metadata": {},
   "source": [
    "## 3. Data Quality Metrics\n",
    "\n",
    "Analyzing data completeness, null values, and data integrity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "data_quality_analysis",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ” Data Quality Analysis\n",
      "=========================\n",
      "âŒ Data quality analysis failed: Catalog Error: Table with name carrier_invoice_data does not exist!\n",
      "Did you mean \"carrier_invoice_extraction.carrier_invoice_data\"?\n",
      "\n",
      "LINE 1: SELECT COUNT(*) FROM carrier_invoice_extraction.carrier_invoice_data\n",
      "                             ^\n"
     ]
    }
   ],
   "source": [
    "# Data quality analysis\n",
    "print(\"ðŸ” Data Quality Analysis\")\n",
    "print(\"=\" * 25)\n",
    "\n",
    "if conn is None:\n",
    "    print(\"âŒ No database connection available\")\n",
    "else:\n",
    "    try:\n",
    "        main_table = \"carrier_invoice_extraction.carrier_invoice_data\"\n",
    "        \n",
    "        # Get total record count for percentage calculations\n",
    "        total_records = conn.execute(f\"SELECT COUNT(*) FROM {main_table}\").fetchone()[0]\n",
    "        \n",
    "        # Key business columns to analyze\n",
    "        key_columns = [\n",
    "            'invoice_number',\n",
    "            'invoice_date', \n",
    "            'invoice_amount',\n",
    "            'invoice_currency_code',\n",
    "            'tracking_number',\n",
    "            'sender_company_name',\n",
    "            'receiver_company_name',\n",
    "            'charge_description',\n",
    "            'net_amount'\n",
    "        ]\n",
    "        \n",
    "        print(f\"ðŸ“Š Data Completeness Analysis (Total Records: {total_records:,}):\")\n",
    "        print()\n",
    "        \n",
    "        completeness_data = []\n",
    "        \n",
    "        for column in key_columns:\n",
    "            try:\n",
    "                # Count non-null, non-empty values\n",
    "                valid_count = conn.execute(f\"\"\"\n",
    "                    SELECT COUNT(*) \n",
    "                    FROM {main_table}\n",
    "                    WHERE {column} IS NOT NULL AND {column} != ''\n",
    "                \"\"\").fetchone()[0]\n",
    "                \n",
    "                # Count null values\n",
    "                null_count = conn.execute(f\"\"\"\n",
    "                    SELECT COUNT(*) \n",
    "                    FROM {main_table}\n",
    "                    WHERE {column} IS NULL\n",
    "                \"\"\").fetchone()[0]\n",
    "                \n",
    "                # Count empty string values\n",
    "                empty_count = conn.execute(f\"\"\"\n",
    "                    SELECT COUNT(*) \n",
    "                    FROM {main_table}\n",
    "                    WHERE {column} = ''\n",
    "                \"\"\").fetchone()[0]\n",
    "                \n",
    "                completeness_pct = (valid_count / total_records) * 100\n",
    "                missing_count = null_count + empty_count\n",
    "                \n",
    "                completeness_data.append({\n",
    "                    'Column': column,\n",
    "                    'Valid Count': valid_count,\n",
    "                    'Missing Count': missing_count,\n",
    "                    'Completeness %': completeness_pct\n",
    "                })\n",
    "                \n",
    "                # Color coding for completeness\n",
    "                if completeness_pct >= 95:\n",
    "                    status = \"âœ… Excellent\"\n",
    "                elif completeness_pct >= 80:\n",
    "                    status = \"ðŸŸ¡ Good\"\n",
    "                elif completeness_pct >= 50:\n",
    "                    status = \"ðŸŸ  Fair\"\n",
    "                else:\n",
    "                    status = \"âŒ Poor\"\n",
    "                \n",
    "                print(f\"   {column:25} | {valid_count:>8,} valid | {missing_count:>8,} missing | {completeness_pct:>6.1f}% | {status}\")\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"   {column:25} | âŒ Analysis failed: {e}\")\n",
    "        \n",
    "        # Summary statistics\n",
    "        if completeness_data:\n",
    "            df_completeness = pd.DataFrame(completeness_data)\n",
    "            avg_completeness = df_completeness['Completeness %'].mean()\n",
    "            \n",
    "            print(f\"\\nðŸ“ˆ Data Quality Summary:\")\n",
    "            print(f\"   Average Completeness: {avg_completeness:.1f}%\")\n",
    "            print(f\"   Columns with >95% completeness: {len(df_completeness[df_completeness['Completeness %'] >= 95])}\")\n",
    "            print(f\"   Columns with <50% completeness: {len(df_completeness[df_completeness['Completeness %'] < 50])}\")\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Data quality analysis failed: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "sample_data_analysis",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“‹ Sample Data Analysis\n",
      "=========================\n",
      "ðŸ“Š Sample Records (Key Fields):\n",
      "âŒ Sample data analysis failed: Catalog Error: Table with name carrier_invoice_data does not exist!\n",
      "Did you mean \"carrier_invoice_extraction.carrier_invoice_data\"?\n",
      "\n",
      "LINE 13:             FROM carrier_invoice_extraction.carrier_invoice_data\n",
      "                          ^\n"
     ]
    }
   ],
   "source": [
    "# Sample data analysis\n",
    "print(\"ðŸ“‹ Sample Data Analysis\")\n",
    "print(\"=\" * 25)\n",
    "\n",
    "if conn is None:\n",
    "    print(\"âŒ No database connection available\")\n",
    "else:\n",
    "    try:\n",
    "        main_table = \"carrier_invoice_extraction.carrier_invoice_data\"\n",
    "        \n",
    "        # Get sample records with key fields\n",
    "        print(\"ðŸ“Š Sample Records (Key Fields):\")\n",
    "        sample_query = f\"\"\"\n",
    "            SELECT \n",
    "                invoice_number,\n",
    "                invoice_date,\n",
    "                invoice_amount,\n",
    "                invoice_currency_code,\n",
    "                tracking_number,\n",
    "                sender_company_name,\n",
    "                receiver_company_name,\n",
    "                charge_description,\n",
    "                net_amount,\n",
    "                import_time\n",
    "            FROM {main_table}\n",
    "            ORDER BY import_time DESC\n",
    "            LIMIT 5\n",
    "        \"\"\"\n",
    "        \n",
    "        sample_df = conn.execute(sample_query).df()\n",
    "        \n",
    "        if not sample_df.empty:\n",
    "            # Display sample with better formatting\n",
    "            pd.set_option('display.max_columns', None)\n",
    "            pd.set_option('display.width', None)\n",
    "            pd.set_option('display.max_colwidth', 30)\n",
    "            \n",
    "            print(sample_df.to_string(index=False))\n",
    "            \n",
    "            print(f\"\\nâœ… Sample data shows {len(sample_df)} recent records\")\n",
    "        else:\n",
    "            print(\"âŒ No sample data available\")\n",
    "        \n",
    "        # Data validation checks\n",
    "        print(f\"\\nðŸ” Data Validation Checks:\")\n",
    "        \n",
    "        # Check for duplicate invoice numbers\n",
    "        try:\n",
    "            duplicate_invoices = conn.execute(f\"\"\"\n",
    "                SELECT COUNT(*) \n",
    "                FROM (\n",
    "                    SELECT invoice_number, COUNT(*) as cnt\n",
    "                    FROM {main_table}\n",
    "                    WHERE invoice_number IS NOT NULL AND invoice_number != ''\n",
    "                    GROUP BY invoice_number\n",
    "                    HAVING COUNT(*) > 1\n",
    "                ) duplicates\n",
    "            \"\"\").fetchone()[0]\n",
    "            \n",
    "            print(f\"   Duplicate Invoice Numbers: {duplicate_invoices:,}\")\n",
    "        except Exception as e:\n",
    "            print(f\"   âŒ Duplicate check failed: {e}\")\n",
    "        \n",
    "        # Check for invalid amounts\n",
    "        try:\n",
    "            invalid_amounts = conn.execute(f\"\"\"\n",
    "                SELECT COUNT(*) \n",
    "                FROM {main_table}\n",
    "                WHERE invoice_amount IS NOT NULL \n",
    "                AND invoice_amount != ''\n",
    "                AND TRY_CAST(invoice_amount AS DECIMAL) IS NULL\n",
    "            \"\"\").fetchone()[0]\n",
    "            \n",
    "            print(f\"   Invalid Amount Values: {invalid_amounts:,}\")\n",
    "        except Exception as e:\n",
    "            print(f\"   âŒ Amount validation failed: {e}\")\n",
    "        \n",
    "        # Check for future dates\n",
    "        try:\n",
    "            future_dates = conn.execute(f\"\"\"\n",
    "                SELECT COUNT(*) \n",
    "                FROM {main_table}\n",
    "                WHERE invoice_date > CURRENT_DATE\n",
    "            \"\"\").fetchone()[0]\n",
    "            \n",
    "            print(f\"   Future Invoice Dates: {future_dates:,}\")\n",
    "        except Exception as e:\n",
    "            print(f\"   âŒ Date validation failed: {e}\")\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Sample data analysis failed: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "file_comparison",
   "metadata": {},
   "source": [
    "## 4. File Information & Comparison\n",
    "\n",
    "Detailed file information and comparison with source data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "file_information",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“ File Information Analysis\n",
      "==============================\n",
      "ðŸ“Š File System Information:\n",
      "   File Path: c:\\Users\\Gabriel\\Documents\\gsr_project\\gsr_automation\\carrier_invoice_extraction.duckdb\n",
      "   File Size: 24.51 MB (0.024 GB)\n",
      "   Created: 2025-09-08 20:13:17\n",
      "   Modified: 2025-09-08 19:49:20\n",
      "   Last Accessed: 2025-09-08 20:33:25\n",
      "\n",
      "ðŸ—„ï¸ Database Metadata:\n",
      "   âŒ Extraction metadata failed: Catalog Error: Table with name carrier_invoice_data does not exist!\n",
      "Did you mean \"carrier_invoice_extraction.carrier_invoice_data\"?\n",
      "\n",
      "LINE 7:                 FROM carrier_invoice_extraction.carrier_invoice_data\n",
      "                             ^\n",
      "   âŒ DLT metadata failed: Catalog Error: Table with name carrier_invoice_data does not exist!\n",
      "Did you mean \"carrier_invoice_extraction.carrier_invoice_data\"?\n",
      "\n",
      "LINE 5:                 FROM carrier_invoice_extraction.carrier_invoice_data\n",
      "                             ^\n",
      "âŒ File information analysis failed: Catalog Error: Table with name carrier_invoice_data does not exist!\n",
      "Did you mean \"carrier_invoice_extraction.carrier_invoice_data\"?\n",
      "\n",
      "LINE 1: SELECT COUNT(*) FROM carrier_invoice_extraction.carrier_invoice_data\n",
      "                             ^\n"
     ]
    }
   ],
   "source": [
    "# Comprehensive file information\n",
    "print(\"ðŸ“ File Information Analysis\")\n",
    "print(\"=\" * 30)\n",
    "\n",
    "if conn is None:\n",
    "    print(\"âŒ No database connection available\")\n",
    "else:\n",
    "    try:\n",
    "        # File system information\n",
    "        file_stats = os.stat(db_path)\n",
    "        file_size_bytes = file_stats.st_size\n",
    "        file_size_mb = file_size_bytes / (1024 * 1024)\n",
    "        file_size_gb = file_size_mb / 1024\n",
    "        \n",
    "        created_time = datetime.fromtimestamp(file_stats.st_ctime)\n",
    "        modified_time = datetime.fromtimestamp(file_stats.st_mtime)\n",
    "        accessed_time = datetime.fromtimestamp(file_stats.st_atime)\n",
    "        \n",
    "        print(f\"ðŸ“Š File System Information:\")\n",
    "        print(f\"   File Path: {os.path.abspath(db_path)}\")\n",
    "        print(f\"   File Size: {file_size_mb:.2f} MB ({file_size_gb:.3f} GB)\")\n",
    "        print(f\"   Created: {created_time.strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "        print(f\"   Modified: {modified_time.strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "        print(f\"   Last Accessed: {accessed_time.strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "        \n",
    "        # Database metadata\n",
    "        print(f\"\\nðŸ—„ï¸ Database Metadata:\")\n",
    "        \n",
    "        main_table = \"carrier_invoice_extraction.carrier_invoice_data\"\n",
    "        \n",
    "        # Get extraction metadata\n",
    "        try:\n",
    "            extraction_info = conn.execute(f\"\"\"\n",
    "                SELECT \n",
    "                    MIN(_extracted_at) as first_extraction,\n",
    "                    MAX(_extracted_at) as last_extraction,\n",
    "                    COUNT(DISTINCT _dlt_load_id) as load_sessions,\n",
    "                    COUNT(DISTINCT _source_table) as source_tables\n",
    "                FROM {main_table}\n",
    "                WHERE _extracted_at IS NOT NULL\n",
    "            \"\"\").fetchone()\n",
    "            \n",
    "            print(f\"   First Extraction: {extraction_info[0]}\")\n",
    "            print(f\"   Last Extraction: {extraction_info[1]}\")\n",
    "            print(f\"   Load Sessions: {extraction_info[2]}\")\n",
    "            print(f\"   Source Tables: {extraction_info[3]}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"   âŒ Extraction metadata failed: {e}\")\n",
    "        \n",
    "        # DLT metadata\n",
    "        try:\n",
    "            dlt_info = conn.execute(f\"\"\"\n",
    "                SELECT \n",
    "                    COUNT(DISTINCT _dlt_load_id) as unique_loads,\n",
    "                    COUNT(DISTINCT _dlt_id) as unique_dlt_ids\n",
    "                FROM {main_table}\n",
    "            \"\"\").fetchone()\n",
    "            \n",
    "            print(f\"   DLT Load IDs: {dlt_info[0]}\")\n",
    "            print(f\"   DLT Record IDs: {dlt_info[1]}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"   âŒ DLT metadata failed: {e}\")\n",
    "        \n",
    "        # Storage efficiency\n",
    "        total_records = conn.execute(f\"SELECT COUNT(*) FROM {main_table}\").fetchone()[0]\n",
    "        total_columns = len(conn.execute(f\"DESCRIBE {main_table}\").fetchall())\n",
    "        \n",
    "        bytes_per_record = file_size_bytes / total_records if total_records > 0 else 0\n",
    "        \n",
    "        print(f\"\\nðŸ“ˆ Storage Efficiency:\")\n",
    "        print(f\"   Records: {total_records:,}\")\n",
    "        print(f\"   Columns: {total_columns}\")\n",
    "        print(f\"   Bytes per Record: {bytes_per_record:.2f}\")\n",
    "        print(f\"   Estimated CSV Size: {(bytes_per_record * total_records * 1.5) / (1024*1024):.2f} MB\")\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ File information analysis failed: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "clickhouse_comparison",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”„ ClickHouse Source Comparison\n",
      "===================================\n",
      "ðŸ“¡ Attempting to connect to ClickHouse source...\n"
     ]
    }
   ],
   "source": [
    "# Compare with ClickHouse source (if accessible)\n",
    "print(\"ðŸ”„ ClickHouse Source Comparison\")\n",
    "print(\"=\" * 35)\n",
    "\n",
    "try:\n",
    "    import clickhouse_connect\n",
    "    \n",
    "    print(\"ðŸ“¡ Attempting to connect to ClickHouse source...\")\n",
    "    \n",
    "    # Connect to ClickHouse\n",
    "    ch_client = clickhouse_connect.get_client(\n",
    "        host=\"pgy8egpix3.us-east-1.aws.clickhouse.cloud\",\n",
    "        port=8443,\n",
    "        username=\"gabriellapuz\",\n",
    "        password=\"PTN.776)RR3s\",\n",
    "        database=\"peerdb\",\n",
    "        secure=True,\n",
    "    )\n",
    "    \n",
    "    print(\"âœ… Connected to ClickHouse successfully!\")\n",
    "    \n",
    "    # Compare record counts\n",
    "    ch_table = \"carrier_carrier_invoice_original_flat_ups\"\n",
    "    ch_total = ch_client.command(f\"SELECT COUNT(*) FROM {ch_table}\")\n",
    "    \n",
    "    if conn:\n",
    "        duck_total = conn.execute(f\"SELECT COUNT(*) FROM carrier_invoice_extraction.carrier_invoice_data\").fetchone()[0]\n",
    "        \n",
    "        print(f\"\\nðŸ“Š Record Count Comparison:\")\n",
    "        print(f\"   ClickHouse Source: {ch_total:,} records\")\n",
    "        print(f\"   DuckDB Extract: {duck_total:,} records\")\n",
    "        \n",
    "        coverage_pct = (duck_total / ch_total) * 100 if ch_total > 0 else 0\n",
    "        print(f\"   Coverage: {coverage_pct:.2f}%\")\n",
    "        \n",
    "        if coverage_pct < 100:\n",
    "            missing_records = ch_total - duck_total\n",
    "            print(f\"   Missing Records: {missing_records:,}\")\n",
    "            print(f\"   ðŸ’¡ This is expected for incremental extractions\")\n",
    "    \n",
    "    # Compare latest data timestamps\n",
    "    try:\n",
    "        ch_latest = ch_client.command(f\"SELECT MAX(import_time) FROM {ch_table}\")\n",
    "        \n",
    "        if conn:\n",
    "            duck_latest = conn.execute(f\"SELECT MAX(import_time) FROM carrier_invoice_extraction.carrier_invoice_data\").fetchone()[0]\n",
    "            \n",
    "            print(f\"\\nðŸ“… Latest Data Comparison:\")\n",
    "            print(f\"   ClickHouse Latest: {ch_latest}\")\n",
    "            print(f\"   DuckDB Latest: {duck_latest}\")\n",
    "            \n",
    "            if str(ch_latest) == str(duck_latest):\n",
    "                print(f\"   âœ… Data is up to date\")\n",
    "            else:\n",
    "                print(f\"   ðŸŸ¡ Data may need updating\")\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"   âŒ Timestamp comparison failed: {e}\")\n",
    "    \n",
    "    ch_client.close()\n",
    "    \n",
    "except ImportError:\n",
    "    print(\"âŒ ClickHouse library not available for comparison\")\n",
    "    print(\"ðŸ’¡ Install with: pip install clickhouse-connect\")\n",
    "except Exception as e:\n",
    "    print(f\"âŒ ClickHouse comparison failed: {e}\")\n",
    "    print(\"ðŸ’¡ This is normal if ClickHouse is not accessible\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "summary_report",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“‹ Comprehensive Analysis Summary\n",
      "========================================\n",
      "ðŸŽ¯ DATASET OVERVIEW:\n",
      "   ðŸ“Š Total Records: 935,481\n",
      "   ðŸ“‹ Total Columns: 263\n",
      "   ðŸ’¾ File Size: 203.51 MB\n",
      "   ðŸ“… Date Range: 2025-07-05 to 2025-08-23\n",
      "   ðŸ”‘ Unique Invoices: 1,126\n",
      "\n",
      "âœ… ANALYSIS COMPLETE:\n",
      "   ðŸ“ DuckDB file successfully analyzed\n",
      "   ðŸ” Data structure documented\n",
      "   ðŸ“Š Statistics calculated\n",
      "   ðŸŽ¯ Quality metrics assessed\n",
      "\n",
      "ðŸ’¡ NEXT STEPS:\n",
      "   ðŸ“Š Use the CSV export notebook to extract data\n",
      "   ðŸ“ˆ Perform business analysis on the dataset\n",
      "   ðŸ”„ Schedule regular pipeline updates\n",
      "   ðŸ“‹ Monitor data quality over time\n",
      "\n",
      "ðŸ”’ Database connection closed\n"
     ]
    }
   ],
   "source": [
    "# Generate comprehensive summary report\n",
    "print(\"ðŸ“‹ Comprehensive Analysis Summary\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "if conn is None:\n",
    "    print(\"âŒ No database connection available for summary\")\n",
    "else:\n",
    "    try:\n",
    "        main_table = \"carrier_invoice_extraction.carrier_invoice_data\"\n",
    "        \n",
    "        # Collect key metrics\n",
    "        total_records = conn.execute(f\"SELECT COUNT(*) FROM {main_table}\").fetchone()[0]\n",
    "        total_columns = len(conn.execute(f\"DESCRIBE {main_table}\").fetchall())\n",
    "        \n",
    "        # File info\n",
    "        file_size_mb = os.path.getsize(db_path) / (1024 * 1024)\n",
    "        \n",
    "        # Date ranges\n",
    "        try:\n",
    "            date_range = conn.execute(f\"\"\"\n",
    "                SELECT \n",
    "                    MIN(invoice_date) as earliest,\n",
    "                    MAX(invoice_date) as latest\n",
    "                FROM {main_table}\n",
    "                WHERE invoice_date IS NOT NULL AND invoice_date != ''\n",
    "            \"\"\").fetchone()\n",
    "        except:\n",
    "            date_range = (\"Unknown\", \"Unknown\")\n",
    "        \n",
    "        # Unique identifiers\n",
    "        try:\n",
    "            unique_invoices = conn.execute(f\"\"\"\n",
    "                SELECT COUNT(DISTINCT invoice_number) \n",
    "                FROM {main_table}\n",
    "                WHERE invoice_number IS NOT NULL AND invoice_number != ''\n",
    "            \"\"\").fetchone()[0]\n",
    "        except:\n",
    "            unique_invoices = \"Unknown\"\n",
    "        \n",
    "        print(f\"ðŸŽ¯ DATASET OVERVIEW:\")\n",
    "        print(f\"   ðŸ“Š Total Records: {total_records:,}\")\n",
    "        print(f\"   ðŸ“‹ Total Columns: {total_columns}\")\n",
    "        print(f\"   ðŸ’¾ File Size: {file_size_mb:.2f} MB\")\n",
    "        print(f\"   ðŸ“… Date Range: {date_range[0]} to {date_range[1]}\")\n",
    "        print(f\"   ðŸ”‘ Unique Invoices: {unique_invoices:,}\" if isinstance(unique_invoices, int) else f\"   ðŸ”‘ Unique Invoices: {unique_invoices}\")\n",
    "        \n",
    "        print(f\"\\nâœ… ANALYSIS COMPLETE:\")\n",
    "        print(f\"   ðŸ“ DuckDB file successfully analyzed\")\n",
    "        print(f\"   ðŸ” Data structure documented\")\n",
    "        print(f\"   ðŸ“Š Statistics calculated\")\n",
    "        print(f\"   ðŸŽ¯ Quality metrics assessed\")\n",
    "        \n",
    "        print(f\"\\nðŸ’¡ NEXT STEPS:\")\n",
    "        print(f\"   ðŸ“Š Use the CSV export notebook to extract data\")\n",
    "        print(f\"   ðŸ“ˆ Perform business analysis on the dataset\")\n",
    "        print(f\"   ðŸ”„ Schedule regular pipeline updates\")\n",
    "        print(f\"   ðŸ“‹ Monitor data quality over time\")\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Summary generation failed: {e}\")\n",
    "\n",
    "# Close connection\n",
    "if conn:\n",
    "    conn.close()\n",
    "    print(f\"\\nðŸ”’ Database connection closed\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "src-B4Ior-7e-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
